{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a2d925f",
   "metadata": {},
   "source": [
    "# 06 — Train/Test Scenario Construction\n",
    "\n",
    "In this notebook we define a reproducible set of *evaluation windows* for\n",
    "testing imputation and forecasting under sensor blackouts.\n",
    "\n",
    "The idea is:\n",
    "\n",
    "- Use **realistic blackout lengths** inspired by the empirical blackout\n",
    "  statistics (10–120 minutes and beyond).\n",
    "- But select **time intervals where the underlying data are fully observed**\n",
    "  and **we artificially hide** the readings during those windows.\n",
    "- For each chosen blackout interval on a given detector, we evaluate:\n",
    "  - **Imputation**: recovering the hidden readings *inside* the blackout.\n",
    "  - **Forecasting**: predicting the first few steps *after* the blackout\n",
    "    (here: +1, +3, +6 steps).\n",
    "\n",
    "The final output is a manifest `evaluation_windows.parquet` that specifies\n",
    "which detector/time windows belong to which evaluation scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5b5a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9259ae82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded clean panel from parquet.\n",
      "wide shape: (105120, 147)\n",
      "Time span: 2015-01-01 00:00:00 → 2015-12-31 23:55:00\n",
      "Loaded m_t.npy; fraction missing: 0.051772771513476014\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# 1. Load cleaned panel + missingness matrix\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Same clean panel as in earlier steps\n",
    "try:\n",
    "    wide = pd.read_parquet(\"data/seattle_loop_clean.parquet\")\n",
    "    print(\"Loaded clean panel from parquet.\")\n",
    "except Exception as e:\n",
    "    print(\"Parquet load failed, falling back to pickle. Error was:\")\n",
    "    print(\" \", e)\n",
    "    wide = pd.read_pickle(\"data/seattle_loop_clean.pkl\")\n",
    "    print(\"Loaded clean panel from pickle.\")\n",
    "\n",
    "X = wide.to_numpy(dtype=np.float32)\n",
    "timestamps = wide.index.to_numpy()\n",
    "detectors = wide.columns.to_numpy()\n",
    "T, D = X.shape\n",
    "\n",
    "print(\"wide shape:\", X.shape)\n",
    "print(\"Time span:\", wide.index.min(), \"→\", wide.index.max())\n",
    "\n",
    "# Missingness matrix M[t, d] = 1 if missing, 0 if observed\n",
    "M = np.load(\"data/m_t.npy\")\n",
    "assert M.shape == X.shape, \"M and X must have same shape\"\n",
    "print(\"Loaded m_t.npy; fraction missing:\", M.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50410b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# 2. Helper: find contiguous True streaks\n",
    "# ------------------------------------------------\n",
    "\n",
    "def find_streaks(bool_array):\n",
    "    \"\"\"\n",
    "    Given a 1D boolean array, return a list of (start, end) indices\n",
    "    for contiguous True runs (inclusive).\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    start = None\n",
    "    for i, v in enumerate(bool_array):\n",
    "        if v and start is None:\n",
    "            start = i\n",
    "        elif not v and start is not None:\n",
    "            out.append((start, i - 1))\n",
    "            start = None\n",
    "    if start is not None:\n",
    "        out.append((start, len(bool_array) - 1))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d090a0e5",
   "metadata": {},
   "source": [
    "## 3. Design choices for evaluation windows\n",
    "\n",
    "We want evaluation windows that:\n",
    "\n",
    "1. **Use realistic blackout lengths**, inspired by the EDA:\n",
    "   - Many blackouts last 30–120 minutes.\n",
    "   - Some are longer (multi-hour outages).\n",
    "\n",
    "2. **Have full ground truth**:\n",
    "   - All readings for that detector must currently be **observed** (non-NaN)\n",
    "     within the blackout interval and the post-blackout horizon.\n",
    "   - We can then temporarily hide those values during evaluation and compare\n",
    "     predictions against the original speeds.\n",
    "\n",
    "3. Cover both **imputation** and **forecasting**:\n",
    "   - **Imputation**: inside the blackout.\n",
    "   - **Forecasting**: first few steps after blackout end, at horizons  \n",
    "     $h \\in \\{1, 3, 6\\}$ (i.e., $+5$, $+15$, $+30$ minutes).\n",
    "\n",
    "We implement this by scanning for long, fully observed stretches of data for\n",
    "each detector and carving out blackout windows inside them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a42539c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total evaluation windows (unique window_id): 441\n",
      "Total manifest rows (impute + forecast): 1764\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# 3. Construct evaluation windows\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Parameters (you can tweak these)\n",
    "BLACKOUT_LENGTHS = [6, 12, 24]      # in steps: 30, 60, 120 minutes\n",
    "FORECAST_HORIZONS = [1, 3, 6]       # steps after blackout_end\n",
    "MAX_WINDOWS_PER_DET = 3             # avoid having too many windows per detector\n",
    "\n",
    "max_h = max(FORECAST_HORIZONS)\n",
    "all_rows = []\n",
    "window_id = 0\n",
    "\n",
    "# Global RNG so randomness is reproducible\n",
    "rng = np.random.default_rng(111)\n",
    "\n",
    "for d_idx, det in enumerate(detectors):\n",
    "    # Boolean array: True if this detector is observed at time t\n",
    "    obs = (M[:, d_idx] == 0)\n",
    "\n",
    "    # Find contiguous fully-observed stretches, then shuffle their order\n",
    "    obs_streaks = find_streaks(obs)\n",
    "    if len(obs_streaks) == 0:\n",
    "        continue\n",
    "    obs_streaks = list(obs_streaks)\n",
    "    obs_streaks = list(rng.permutation(obs_streaks))\n",
    "\n",
    "    used_for_det = 0\n",
    "\n",
    "    for (s, e) in obs_streaks:\n",
    "        if used_for_det >= MAX_WINDOWS_PER_DET:\n",
    "             break\n",
    "\n",
    "        streak_len = e - s + 1\n",
    "        # We need enough length to fit blackout + max forecast horizon\n",
    "        min_required = min(BLACKOUT_LENGTHS) + max_h\n",
    "        if streak_len < min_required:\n",
    "            continue\n",
    "\n",
    "        def pick_offset_mnar_weighted(X, d_idx, s, e, required, rng):\n",
    "            \"\"\"\n",
    "            Pick blackout offset with higher probability when the *pre-blackout*\n",
    "            regime is extreme/volatile (synthetic MNAR stress test).\n",
    "            \"\"\"\n",
    "            # candidate blackout_start indices (must have at least one pre-step)\n",
    "            starts = np.arange(s + 1, e - required + 2)  # inclusive\n",
    "            if starts.size == 0:\n",
    "                return None\n",
    "\n",
    "            pre = starts - 1\n",
    "            x_pre = X[pre, d_idx]\n",
    "            # rolling variance proxy over last 12 steps (1 hour) using finite values only\n",
    "            roll = np.zeros_like(x_pre, dtype=float)\n",
    "            for i, t0 in enumerate(pre):\n",
    "                w = X[max(0, t0-12):t0, d_idx]\n",
    "                w = w[np.isfinite(w)]\n",
    "                roll[i] = np.var(w) if w.size >= 3 else 0.0\n",
    "\n",
    "            # weights: extreme speeds + volatility\n",
    "            xz = (x_pre - np.nanmean(X[:, d_idx])) / (np.nanstd(X[:, d_idx]) + 1e-6)\n",
    "            score = np.abs(xz) + 0.15 * np.sqrt(roll)\n",
    "            score = np.nan_to_num(score, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            w = np.exp(np.clip(score, 0.0, 6.0))\n",
    "            w = w / (w.sum() + 1e-12)\n",
    "            start = rng.choice(starts, p=w)\n",
    "            offset = int(start - (s + 1))\n",
    "            return offset\n",
    "\n",
    "\n",
    "        for L in BLACKOUT_LENGTHS:\n",
    "            required = L + max_h\n",
    "            if streak_len < required:\n",
    "                continue\n",
    "\n",
    "            required = L + max_h  # already defined above\n",
    "            available = (e - s + 1) - required   # how many positions we can slide\n",
    "            if available < 0:\n",
    "                continue\n",
    "\n",
    "            # MNAR-weighted offset (synthetic stress test)\n",
    "            offset = pick_offset_mnar_weighted(X, d_idx, s, e, required, rng)\n",
    "            if offset is None:\n",
    "                continue\n",
    "            blackout_start = s + 1 + offset\n",
    "            blackout_end = blackout_start + L - 1\n",
    "\n",
    "            # Check again that we have room for max horizon\n",
    "            if blackout_end + max_h > e:\n",
    "                continue\n",
    "\n",
    "            # Sanity check: all points we rely on (blackout + horizon) must be observed\n",
    "            seg_ok = obs[blackout_start : blackout_end + max_h + 1].all()\n",
    "            if not seg_ok:\n",
    "                continue\n",
    "\n",
    "            # We now have a valid evaluation window\n",
    "            # 1) imputation window row\n",
    "            all_rows.append({\n",
    "                \"window_id\": window_id,\n",
    "                \"detector_id\": det,\n",
    "                \"blackout_start\": timestamps[blackout_start],\n",
    "                \"blackout_end\": timestamps[blackout_end],\n",
    "                \"len_steps\": L,               # blackout length in 5-min steps\n",
    "                \"test_type\": \"impute\",\n",
    "                \"horizon_steps\": np.nan,      # not used for imputation\n",
    "                \"scenario\": \"mnar_weighted\",\n",
    "            })\n",
    "\n",
    "            # 2) forecasting rows for each horizon\n",
    "            for h in FORECAST_HORIZONS:\n",
    "                forecast_time = timestamps[blackout_end + h]\n",
    "                all_rows.append({\n",
    "                    \"window_id\": window_id,\n",
    "                    \"detector_id\": det,\n",
    "                    \"blackout_start\": timestamps[blackout_start],\n",
    "                    \"blackout_end\": timestamps[blackout_end],\n",
    "                    \"len_steps\": L,          \n",
    "                    \"test_type\": \"forecast\",\n",
    "                    \"horizon_steps\": h,\n",
    "                    \"scenario\": \"mnar_weighted\",\n",
    "                })\n",
    "\n",
    "            window_id += 1\n",
    "            used_for_det += 1\n",
    "\n",
    "            if used_for_det >= MAX_WINDOWS_PER_DET:\n",
    "                break  # stop after enough windows for this detector\n",
    "\n",
    "print(f\"Total evaluation windows (unique window_id): {window_id}\")\n",
    "print(f\"Total manifest rows (impute + forecast): {len(all_rows)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3360f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   window_id detector_id      blackout_start        blackout_end  len_steps  \\\n",
      "0          0  005es15036 2015-06-01 16:55:00 2015-06-01 17:20:00          6   \n",
      "1          0  005es15036 2015-06-01 16:55:00 2015-06-01 17:20:00          6   \n",
      "2          0  005es15036 2015-06-01 16:55:00 2015-06-01 17:20:00          6   \n",
      "3          0  005es15036 2015-06-01 16:55:00 2015-06-01 17:20:00          6   \n",
      "4          1  005es15036 2015-07-11 07:55:00 2015-07-11 08:50:00         12   \n",
      "\n",
      "  test_type  horizon_steps       scenario  \n",
      "0    impute            NaN  mnar_weighted  \n",
      "1  forecast            1.0  mnar_weighted  \n",
      "2  forecast            3.0  mnar_weighted  \n",
      "3  forecast            6.0  mnar_weighted  \n",
      "4    impute            NaN  mnar_weighted  \n",
      "\n",
      "Summary by test_type:\n",
      "test_type\n",
      "forecast    1323\n",
      "impute       441\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Saved evaluation manifest to: C:\\Users\\Dell\\Downloads\\Modeling-Information-Blackouts-in-MNAR-Time-Series-main\\Modeling-Information-Blackouts-in-MNAR-Time-Series-main\\data\\evaluation_windows_mnar_weighted.parquet\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# 4. Build manifest DataFrame and save\n",
    "# ------------------------------------------------\n",
    "\n",
    "eval_df = pd.DataFrame(all_rows)\n",
    "\n",
    "print(eval_df.head())\n",
    "print(\"\\nSummary by test_type:\")\n",
    "print(eval_df[\"test_type\"].value_counts())\n",
    "\n",
    "Path(\"data\").mkdir(exist_ok=True)\n",
    "out_path = Path(\"data\") / \"evaluation_windows_mnar_weighted.parquet\"\n",
    "eval_df.to_parquet(out_path, engine=\"pyarrow\", index=False)\n",
    "print(\"\\nSaved evaluation manifest to:\", out_path.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55144b27",
   "metadata": {},
   "source": [
    "## 5. Manifest format and usage\n",
    "\n",
    "The file `data/evaluation_windows.parquet` has one row per evaluation\n",
    "*scenario*, with the following columns:\n",
    "\n",
    "- `window_id`:\n",
    "  - Integer identifier of a blackout window.\n",
    "  - All rows sharing the same `window_id` refer to the same blackout\n",
    "    interval on a specific detector.\n",
    "\n",
    "- `detector_id`:\n",
    "  - String identifier of the loop detector (matches columns of `wide`).\n",
    "\n",
    "- `blackout_start`:\n",
    "  - Timestamp of the first time step inside the blackout (inclusive).\n",
    "\n",
    "- `blackout_end`:\n",
    "  - Timestamp of the last time step inside the blackout (inclusive).\n",
    "\n",
    "- `test_type`:\n",
    "  - `\"impute\"`:\n",
    "    - Evaluate reconstruction of the hidden readings inside the blackout\n",
    "      window `[blackout_start, blackout_end]`.\n",
    "  - `\"forecast\"`:\n",
    "    - Evaluate forecasting at a given horizon after the blackout (see below).\n",
    "\n",
    "- `horizon_steps`:\n",
    "  - For `test_type=\"impute\"`: `0` (meaning inside-window evaluation).\n",
    "  - For `test_type=\"forecast\"`: number of 5-minute steps after\n",
    "    `blackout_end` (here: `1`, `3`, or `6` steps, corresponding to +5,\n",
    "    +15, +30 minutes).\n",
    "\n",
    "### How to apply this in experiments\n",
    "\n",
    "Given a row with (`detector_id`, `blackout_start`, `blackout_end`):\n",
    "\n",
    "1. **Imputation** (`test_type = \"impute\"`):\n",
    "   - Temporarily set `x[t, d]` to `NaN` for all time steps\n",
    "     `t ∈ [blackout_start, blackout_end]` and that detector `d`.\n",
    "   - Run the model and compare the predictions to the original speeds\n",
    "     over that interval.\n",
    "\n",
    "2. **Forecasting** (`test_type = \"forecast\"` with `horizon_steps = h > 0`):\n",
    "   - Use only observations up to `blackout_end` (and possibly the blackout\n",
    "     pattern as context).\n",
    "   - Predict `x[blackout_end + h, d]` and compare to the actual value.\n",
    "\n",
    "Because all windows are chosen from fully observed stretches of data, the\n",
    "“ground truth” speeds are available both inside and after the blackout.\n",
    "This makes the evaluation reproducible and directly comparable across\n",
    "different models and inference schemes.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
